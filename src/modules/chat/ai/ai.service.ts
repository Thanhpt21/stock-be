import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import { PrismaService } from 'prisma/prisma.service';

interface AiOptions {
  model?: string;
  systemPrompt?: string;
  temperature?: number;
  maxTokens?: number;
}

@Injectable()
export class AiService {
  private readonly logger = new Logger(AiService.name);
  private openai: OpenAI;
  private aiChatEnabled = true; // c√≥ th·ªÉ b·∫≠t/t·∫Øt to√†n c·ª•c
  private defaultModel = 'gpt-4o-mini'; // ho·∫∑c model kh√°c
  private defaultPrompt =
    'B·∫°n l√† tr·ª£ l√Ω h·ªó tr·ª£ kh√°ch h√†ng th√¢n thi·ªán, tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† chuy√™n nghi·ªáp.';

  constructor(private prisma: PrismaService) {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }

  // üîπ Ki·ªÉm tra xem AI chat c√≥ b·∫≠t kh√¥ng (global)
  async isAiChatEnabled(): Promise<boolean> {
    return this.aiChatEnabled;
  }

  // üîπ B·∫≠t / t·∫Øt AI chat (global)
  async setAiChatEnabled(enabled: boolean): Promise<boolean> {
    this.aiChatEnabled = enabled;
    this.logger.log(`AI Chat ${enabled ? 'enabled' : 'disabled'}`);
    return this.aiChatEnabled;
  }

  // üîπ T·∫°o ph·∫£n h·ªìi t·ª´ AI (kh√¥ng tenant)
  async generateReply(
    conversationHistory: { senderType: string; message: string }[],
    options?: AiOptions,
  ): Promise<string | null> {
    if (!this.aiChatEnabled) return null;

    const systemPrompt = options?.systemPrompt || this.defaultPrompt;

    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.map((m) => ({
        role: m.senderType === 'USER' ? 'user' : 'assistant',
        content: m.message,
      })),
    ] as unknown as OpenAI.Chat.Completions.ChatCompletionMessageParam[];

    try {
      const completion = await this.openai.chat.completions.create({
        model: options?.model || this.defaultModel,
        temperature: options?.temperature ?? 0.7,
        max_tokens: options?.maxTokens ?? 512,
        messages,
      });

      const reply = completion.choices[0].message?.content ?? null;
      this.logger.log('‚úÖ AI reply generated successfully');
      return reply;
    } catch (error) {
      this.logger.error('‚ùå AI generateReply error:', error);
      return null;
    }
  }
}
